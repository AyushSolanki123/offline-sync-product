# # #!/bin/sh

# # # 0. set API_DIR variable to the value of your API folder
# # API_DIR='dataStoreApi'

# # # 1. copy the base schema to the amplify API input schema
# # cp ./base-schema.graphql amplify/backend/api/$API_DIR/schema.graphql

# # # 2. compile the input schema to generate the build artifacts
# # amplify api gql-compile

# # # 3. build the application models;
# # #    add them to a base-model folder for safe-keeping
# # amplify models codegen
# # mkdir -p ./base-models
# # cp ./src/models/* ./base-models/

# # cd amplify/backend/api/$API_DIR/

# # 4. remove the resolvers generated by the first gql-compile pass
# /bin/rm ./build/resolvers/*
# /bin/rm ./resolvers/*

# 5. Move the build schema to the API input schema
cp ./build/schema.graphql ./schema.graphql

# 6. update the schema query and mutation fields with the @function 
#    directive specying to use the dataStoreLink Lambda function
echo "\nUpdating schema with dataStoreLink function..."
sed -i 's/\(sync.*(filter:.*$\)/\1 @function(name: "dataStoreLink-${env}")/' schema.graphql
sed -i 's/\(create.*(input:.*$\)/\1 @function(name: "dataStoreLink-${env}")/' schema.graphql
sed -i 's/\(update.*(input:.*$\)/\1 @function(name: "dataStoreLink-${env}")/' schema.graphql
sed -i 's/\(delete.*(input:.*$\)/\1 @function(name: "dataStoreLink-${env}")/' schema.graphql

# 7. recompile the schema to generate the final assets
amplify api gql-compile

# 8. copy the response resolvers to the input resolvers folder,
#    and update these files with a custom template
echo "\nUpdating response resolvers...\n"
cp ./build/resolvers/*res.vtl ./resolvers/
do_cat () {
  echo "Updating $1"
  cat << EOF > $1
  #if(\$context.prev.result && \$context.prev.result.errorMessage )
    \$utils.error(\$context.prev.result.errorMessage, \$context.prev.result.errorType,
    \$context.prev.result.data)
  #else
    \$utils.toJson(\$context.prev.result.data)
  #end
EOF
}
export -f do_cat
find ./resolvers -type f -exec sh -c 'do_cat "{}"' \;